{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd060aa7568c9db8113868ebef0220b161e96389b06f6ba9eb98d46b6b0f2cf6a72",
   "display_name": "Python 3.6.8 64-bit ('benchmark': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import scispacy\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from note_processing.heuristic_tokenize import sent_tokenize_rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIR = '/mnt/data01/mimic-3/benchmark-small/test/345' #this path will contain tokenized notes. This dir will be the input dir for create_pretrain_data.sh\n",
    "\n",
    "#this is the path to mimic data if you're reading from a csv. Else uncomment the code to read from database below\n",
    "MIMIC_NOTES_PATHS = ['/mnt/data01/mimic-3/benchmark-small/test',\n",
    "                     '/mnt/data01/mimic-3/benchmark-small/train']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Load note files: 100%|██████████| 43/43 [00:00<00:00, 342.82it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              hours category            description  \\\n",
       "count   1126.000000     1126                   1126   \n",
       "unique          NaN       10                     63   \n",
       "top             NaN  Nursing  Nursing Progress Note   \n",
       "freq            NaN      502                    391   \n",
       "mean      94.009515      NaN                    NaN   \n",
       "std      122.909907      NaN                    NaN   \n",
       "min        0.201111      NaN                    NaN   \n",
       "25%       15.973056      NaN                    NaN   \n",
       "50%       38.878333      NaN                    NaN   \n",
       "75%      110.511389      NaN                    NaN   \n",
       "max      545.461667      NaN                    NaN   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                1126   \n",
       "unique                                               1045   \n",
       "top     68 yo F with extensive PMH: MI x 3; 70 % occlu...   \n",
       "freq                                                    7   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                 filename  \n",
       "count                                                1126  \n",
       "unique                                                 41  \n",
       "top     /mnt/data01/mimic-3/benchmark-small/train/124/...  \n",
       "freq                                                  226  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hours</th>\n      <th>category</th>\n      <th>description</th>\n      <th>text</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1126.000000</td>\n      <td>1126</td>\n      <td>1126</td>\n      <td>1126</td>\n      <td>1126</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>10</td>\n      <td>63</td>\n      <td>1045</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Nursing</td>\n      <td>Nursing Progress Note</td>\n      <td>68 yo F with extensive PMH: MI x 3; 70 % occlu...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/124/...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>502</td>\n      <td>391</td>\n      <td>7</td>\n      <td>226</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94.009515</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>122.909907</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.201111</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>15.973056</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>38.878333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>110.511389</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>545.461667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "all_files = []\n",
    "\n",
    "for path in MIMIC_NOTES_PATHS:\n",
    "    files = glob.glob(path + \"/*/*_notes.csv\")\n",
    "    all_files += files\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in tqdm(all_files, desc=\"Load note files\"):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df[\"filename\"] = filename\n",
    "    li.append(df)\n",
    "\n",
    "notes = pd.concat(li, axis=0, ignore_index=True)\n",
    "notes.columns= notes.columns.str.lower()\n",
    "notes.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      hours       category                 description  \\\n",
       "0  0.201111      Radiology         CHEST (PORTABLE AP)   \n",
       "1  1.034444      Radiology  CHEST PORT. LINE PLACEMENT   \n",
       "2  1.967778      Radiology  CHEST PORT. LINE PLACEMENT   \n",
       "3  7.351111  Nursing/other                      Report   \n",
       "4  7.584444  Nursing/other                      Report   \n",
       "\n",
       "                                                text  \\\n",
       "0  [**2169-5-21**] 10:17 PM\\n CHEST (PORTABLE AP)...   \n",
       "1  [**2169-5-21**] 11:07 PM\\n CHEST PORT. LINE PL...   \n",
       "2  [**2169-5-22**] 12:03 AM\\n CHEST PORT. LINE PL...   \n",
       "3  Respiratory CAre\\nPt received from ED intubate...   \n",
       "4  0000-0700 NPN\\nPt. admitted via ER from [**Hos...   \n",
       "\n",
       "                                            filename  \n",
       "0  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "1  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "2  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "3  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "4  /mnt/data01/mimic-3/benchmark-small/test/345/e...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hours</th>\n      <th>category</th>\n      <th>description</th>\n      <th>text</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.201111</td>\n      <td>Radiology</td>\n      <td>CHEST (PORTABLE AP)</td>\n      <td>[**2169-5-21**] 10:17 PM\\n CHEST (PORTABLE AP)...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.034444</td>\n      <td>Radiology</td>\n      <td>CHEST PORT. LINE PLACEMENT</td>\n      <td>[**2169-5-21**] 11:07 PM\\n CHEST PORT. LINE PL...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.967778</td>\n      <td>Radiology</td>\n      <td>CHEST PORT. LINE PLACEMENT</td>\n      <td>[**2169-5-22**] 12:03 AM\\n CHEST PORT. LINE PL...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.351111</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>Respiratory CAre\\nPt received from ED intubate...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.584444</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>0000-0700 NPN\\nPt. admitted via ER from [**Hos...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "notes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               hours description  text filename\n",
       "               count       count count    count\n",
       "category                                       \n",
       "General           23          23    23       23\n",
       "Nursing          502         502   502      502\n",
       "Nursing/other     50          50    50       50\n",
       "Nutrition         13          13    13       13\n",
       "Pharmacy           2           2     2        2\n",
       "Physician        333         333   333      333\n",
       "Radiology        119         119   119      119\n",
       "Rehab Services     8           8     8        8\n",
       "Respiratory       75          75    75       75\n",
       "Social Work        1           1     1        1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>hours</th>\n      <th>description</th>\n      <th>text</th>\n      <th>filename</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>count</th>\n      <th>count</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>General</th>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>Nursing</th>\n      <td>502</td>\n      <td>502</td>\n      <td>502</td>\n      <td>502</td>\n    </tr>\n    <tr>\n      <th>Nursing/other</th>\n      <td>50</td>\n      <td>50</td>\n      <td>50</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>Nutrition</th>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>Pharmacy</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Physician</th>\n      <td>333</td>\n      <td>333</td>\n      <td>333</td>\n      <td>333</td>\n    </tr>\n    <tr>\n      <th>Radiology</th>\n      <td>119</td>\n      <td>119</td>\n      <td>119</td>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>Rehab Services</th>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>Respiratory</th>\n      <td>75</td>\n      <td>75</td>\n      <td>75</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>Social Work</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "notes.groupby(\"category\").agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aflanders:\n",
    "# This code will split the notes into natural sentence boundaries separated by \\n\n",
    "# which can then be fed into sentence embedding models such as BIO-ClinicalBert or \n",
    "# BioSentVec\n",
    "#\n",
    "# This frame and the next are largly from format_mimic_for_BERT.py in EmilyAlsentzer/clinicalBERT\n",
    "# I have updated the code to work with spacy 3.0 and made some other changes\n",
    "#\n",
    "# Example:\n",
    "# THis is a \n",
    "# single \n",
    "# sentence. and another sentence.\n",
    "\n",
    "# THis is a single sentence.\\n\n",
    "# and another sentence.\\n\n",
    "\n",
    "from spacy.language import Language\n",
    "\n",
    "#setting sentence boundaries\n",
    "@Language.component('sbd_component')\n",
    "def sbd_component(doc):\n",
    "    for i, token in enumerate(doc[:-2]):\n",
    "        # define sentence start if period + titlecase token\n",
    "        if token.text == '.' and doc[i+1].is_title:\n",
    "            doc[i+1].sent_start = True\n",
    "        if token.text == '-' and doc[i+1].text != '-':\n",
    "            doc[i+1].sent_start = True\n",
    "    return doc\n",
    "\n",
    "#convert de-identification text into one token\n",
    "# aflanders: no need to pass in the next separate, is available in processed_text\n",
    "# def fix_deid_tokens(text, processed_text):\n",
    "def fix_deid_tokens(doc):\n",
    "    deid_regex  = r\"\\[\\*\\*.{0,15}.*?\\*\\*\\]\" \n",
    "\n",
    "    indexes = [m.span() for m in re.finditer(deid_regex, doc.text, flags=re.IGNORECASE)]\n",
    "\n",
    "    for start,end in indexes:\n",
    "        # processed_text.merge(start_idx=start,end_idx=end)\n",
    "        # aflanders: Make compatible with latest version fo spacy\n",
    "        try:\n",
    "            span = doc.char_span(start, end)\n",
    "            if span is not None:\n",
    "                with doc.retokenize() as retokenizer:\n",
    "                    # retokenizer.merge(processed_text[start:end+1])\n",
    "                    retokenizer.merge(span)\n",
    "        except:\n",
    "            print(f'Error with: {text}')\n",
    "                \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_section(section, note, processed_sections):\n",
    "    # perform spacy processing on section\n",
    "    processed_section = nlp(section['sections'])\n",
    "    # processed_section = fix_deid_tokens(section['sections'], processed_section)\n",
    "    processed_section = fix_deid_tokens(processed_section)\n",
    "    processed_sections.append(processed_section)\n",
    "\n",
    "def process_note_helper(note):\n",
    "    # split note into sections\n",
    "    note_sections = sent_tokenize_rules(note)\n",
    "    processed_sections = []\n",
    "    section_frame = pd.DataFrame({'sections':note_sections})\n",
    "    section_frame.apply(process_section, args=(note,processed_sections,), axis=1)\n",
    "    return(processed_sections)\n",
    "\n",
    "def process_text(sent, note):\n",
    "    sent_text = sent['sents'].text\n",
    "    if len(sent_text) > 0 and sent_text.strip() != '\\n':\n",
    "        if '\\n' in sent_text:\n",
    "            sent_text = sent_text.replace('\\n', ' ')\n",
    "        note['text'] += sent_text + '\\n'  \n",
    "\n",
    "def get_sentences(processed_section, note):\n",
    "    # get sentences from spacy processing\n",
    "    sent_frame = pd.DataFrame({'sents': list(processed_section['sections'].sents)})\n",
    "    sent_frame.apply(process_text, args=(note,), axis=1)\n",
    "\n",
    "def process_note(note):\n",
    "    try:\n",
    "        note_text = note['text'] #unicode(note['text'])\n",
    "        note['text'] = ''\n",
    "        processed_sections = process_note_helper(note_text)\n",
    "        ps = {'sections': processed_sections}\n",
    "        ps = pd.DataFrame(ps)\n",
    "        ps.apply(get_sentences, args=(note,), axis=1)\n",
    "        return note \n",
    "    except Exception as e:\n",
    "        # pass\n",
    "        print ('error processing note', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\nWall time: 4.53 µs\nBegin reading notes\nNumber of notes: 50\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.sbd_component>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#category = [\"Nursing\", \"Nursing/other\", 'General', 'Physician ']  # or None\n",
    "category = [\"Nursing/other\"]  # or None\n",
    "\n",
    "start = time.time()\n",
    "tqdm.pandas()\n",
    "\n",
    "print('Begin reading notes')\n",
    "\n",
    "if category != None:\n",
    "    notes = notes[notes['category'].isin(category)]\n",
    "print('Number of notes: %d' %len(notes.index))\n",
    "notes['ind'] = list(range(len(notes.index)))\n",
    "\n",
    "nlp = spacy.load('en_core_sci_md', disable=['tagger','ner', 'lemmatizer'])\n",
    "nlp.add_pipe('sbd_component', before='parser')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "filenames = list(notes[\"filename\"].unique().tolist())\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=7), Label(value='0 / 7'))), HBox(c…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be848542622442089df7450516a2bb36"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "formatted_notes = notes.parallel_apply(process_note, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Bio_ClinicalBERT model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't bother trying to run the pipeline without a GPU\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "pipe = pipeline('feature-extraction', model=model, \n",
    "                tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.8.1+cu102\n0\n10020 cuda compiled version\n10.2\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)\n",
    "print(torch.cuda.current_device())\n",
    "print(torch._C._cuda_getCompiledVersion(), 'cuda compiled version')\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.03993218,  0.28045347, -0.2261221 , ..., -0.36056122,\n",
       "         0.0209801 , -0.07117219],\n",
       "       [ 0.26059005,  0.28010401, -0.19884749, ..., -0.41535112,\n",
       "         0.55648154, -0.36985222]])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "features = pipe(['Respiratory CAre Pt received from ED intubated for airway protection.And then another sentenc',\n",
    "                  'Coughing and gagging with Sx, swallowing frequently with irritation of ETT.']  ,\n",
    "                pad_to_max_length=True)\n",
    "features = np.squeeze(features)\n",
    "features = features[:,0,:]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_embeddings(text, pipe):\n",
    "    sents = text.split('\\n')[:-1]\n",
    "    #sents = list(map(lambda x: x[:50], sents))\n",
    "    start_idx = 0\n",
    "    while True:\n",
    "        try:\n",
    "            sent_features = pipe(sents[start_idx:] ,pad_to_max_length=True)\n",
    "        except BaseException as e:\n",
    "            start_idx += 1\n",
    "\n",
    "            if start_idx >= len(sents):\n",
    "                print(\"\\nError in get_embeddings()\")\n",
    "                print('# of sentences: '+ str(len(sents)))\n",
    "                sent_len = [len(x) for x in sents]\n",
    "                print(sent_len)\n",
    "                sent_features = None\n",
    "                break\n",
    "\n",
    "            print(\"Dropping sentence: \" + sents[start_idx-1])\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    if sent_features is not None:\n",
    "        try:\n",
    "            sent_features = np.squeeze(sent_features)[:,0,:]\n",
    "        except:\n",
    "            sent_features = None\n",
    "    \n",
    "    return sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# strings = formatted_notes[\"text\"].tolist()\n",
    "# doc = '\\n'.join(strings)\n",
    "# sents = doc.split('\\n')[:-1]\n",
    "# features = pipe(sents ,\n",
    "#                 pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "formatted_notes[\"embeddings\"] = formatted_notes[\"text\"].progress_apply(get_embeddings, args=(pipe,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7, 768)\n(47, 768)\n(5, 768)\n(71, 768)\n(43, 768)\n(5, 768)\n(51, 768)\n(45, 768)\n(6, 768)\n(28, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(formatted_notes[\"embeddings\"].iloc[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             hours       category description  \\\n",
       "count    50.000000             50          50   \n",
       "unique         NaN              1           1   \n",
       "top            NaN  Nursing/other      Report   \n",
       "freq           NaN             50          50   \n",
       "mean     45.648222            NaN         NaN   \n",
       "std      31.821967            NaN         NaN   \n",
       "min       4.174444            NaN         NaN   \n",
       "25%      21.070764            NaN         NaN   \n",
       "50%      44.101111            NaN         NaN   \n",
       "75%      62.639236            NaN         NaN   \n",
       "max     129.083611            NaN         NaN   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                  50   \n",
       "unique                                                 50   \n",
       "top     Nursing Admission/Progress Note (1335-\\n1900) ...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                 filename       ind  \\\n",
       "count                                                  50  50.00000   \n",
       "unique                                                  7       NaN   \n",
       "top     /mnt/data01/mimic-3/benchmark-small/train/191/...       NaN   \n",
       "freq                                                   20       NaN   \n",
       "mean                                                  NaN  24.50000   \n",
       "std                                                   NaN  14.57738   \n",
       "min                                                   NaN   0.00000   \n",
       "25%                                                   NaN  12.25000   \n",
       "50%                                                   NaN  24.50000   \n",
       "75%                                                   NaN  36.75000   \n",
       "max                                                   NaN  49.00000   \n",
       "\n",
       "                                               embeddings  \n",
       "count                                                  50  \n",
       "unique                                                 50  \n",
       "top     [[0.38307225704193115, 0.34203147888183594, 0....  \n",
       "freq                                                    1  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hours</th>\n      <th>category</th>\n      <th>description</th>\n      <th>text</th>\n      <th>filename</th>\n      <th>ind</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50.000000</td>\n      <td>50</td>\n      <td>50</td>\n      <td>50</td>\n      <td>50</td>\n      <td>50.00000</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>Nursing Admission/Progress Note (1335-\\n1900) ...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/191/...</td>\n      <td>NaN</td>\n      <td>[[0.38307225704193115, 0.34203147888183594, 0....</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>50</td>\n      <td>50</td>\n      <td>1</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>45.648222</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.50000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>31.821967</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.57738</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.174444</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>21.070764</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.25000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>44.101111</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.50000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>62.639236</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36.75000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>129.083611</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>49.00000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "formatted_notes.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      hours       category description  \\\n",
       "3  7.351111  Nursing/other      Report   \n",
       "\n",
       "                                                text  \\\n",
       "3  Respiratory CAre Pt received from ED intubated...   \n",
       "\n",
       "                                            filename  ind  \\\n",
       "3  /mnt/data01/mimic-3/benchmark-small/test/345/e...    0   \n",
       "\n",
       "                                          embeddings  \n",
       "3  [[-0.23393520712852478, -0.19446520507335663, ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hours</th>\n      <th>category</th>\n      <th>description</th>\n      <th>text</th>\n      <th>filename</th>\n      <th>ind</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>7.351111</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>Respiratory CAre Pt received from ED intubated...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n      <td>0</td>\n      <td>[[-0.23393520712852478, -0.19446520507335663, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "formatted_notes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "type(formatted_notes[\"embeddings\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out a new notes file with the embeddings\n",
    "# aflanders: This is going to take too long and take up too much space\n",
    "# The embeddings will be longer than the notes themselves. Each patient/episode\n",
    "# can go from 500Kb to 18Mb\n",
    "\n",
    "# filenames = [filename[\"filename\"].value]\n",
    "# formatted_notes.columns= formatted_notes.columns.str.capitalize()\n",
    "# formatted_notes.rename(columns={\"Embeddings\":\"Bert embeddings\"}, inplace=True)\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# filenames = list(formatted_notes[\"Filename\"].unique().tolist())\n",
    "# for filename in tqdm(filenames, desc=\"Writing embedding files\"):\n",
    "#     df = formatted_notes[formatted_notes[\"Filename\"] == filename][[\"Hours\", \"Category\", \"Description\", \"Bert embeddings\"]]\n",
    "#     write_file = filename.replace(\"_notes.csv\", \"_notes_bert.csv\")\n",
    "#     with open(write_file, \"w\") as f:\n",
    "#         df.to_csv(f, index_label='Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['/mnt/data01/mimic-3/benchmark-small/test/345/episode1_notes.csv', '/mnt/data01/mimic-3/benchmark-small/train/124/episode2_notes.csv', '/mnt/data01/mimic-3/benchmark-small/train/191/episode2_notes.csv', '/mnt/data01/mimic-3/benchmark-small/train/222/episode3_notes.csv', '/mnt/data01/mimic-3/benchmark-small/train/222/episode4_notes.csv', '/mnt/data01/mimic-3/benchmark-small/train/109/episode8_notes.csv', '/mnt/data01/mimic-3/benchmark-small/train/109/episode7_notes.csv']\n"
     ]
    }
   ],
   "source": [
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}