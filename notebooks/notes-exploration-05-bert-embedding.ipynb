{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd060aa7568c9db8113868ebef0220b161e96389b06f6ba9eb98d46b6b0f2cf6a72",
   "display_name": "Python 3.6.8 64-bit ('benchmark': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import scispacy\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from note_processing.heuristic_tokenize import sent_tokenize_rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIR = '/mnt/data01/mimic-3/benchmark-small/test/345' #this path will contain tokenized notes. This dir will be the input dir for create_pretrain_data.sh\n",
    "\n",
    "#this is the path to mimic data if you're reading from a csv. Else uncomment the code to read from database below\n",
    "MIMIC_NOTES_PATHS = ['/mnt/data01/mimic-3/benchmark-small/test',\n",
    "                     '/mnt/data01/mimic-3/benchmark-small/train']  \n",
    "\n",
    "DEVICE = -1  # -1 is CPU otherwise the GPU device id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Load note files: 100%|██████████| 41/41 [00:00<00:00, 218.30it/s]\n",
      "Total note files: 41\n",
      "\n",
      "Total notes: 1126\n"
     ]
    }
   ],
   "source": [
    "all_files = []\n",
    "\n",
    "for path in MIMIC_NOTES_PATHS:\n",
    "    files = glob.glob(path + \"/*/*_notes_sent.csv\")\n",
    "    all_files += files\n",
    "\n",
    "print(f\"\\nTotal note files: {len(all_files)}\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in tqdm(all_files, desc=\"Load note files\"):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df[\"filename\"] = filename\n",
    "    li.append(df)\n",
    "\n",
    "notes = pd.concat(li, axis=0, ignore_index=True)\n",
    "notes.describe(include=\"all\")\n",
    "\n",
    "print(f\"Total notes: {len(notes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add patient to the table\n",
    "notes[\"PATIENT_ID\"] = notes[\"filename\"].apply(lambda x: int(re.findall(r'/[0-9]+/', x)[-1][1:-1]))\n",
    "\n",
    "# Add episode to the table\n",
    "notes[\"EPISODE_ID\"] = notes[\"filename\"].apply(lambda x: int(re.findall(r'episode[0-9]+_', x)[-1][7:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Hours    CATEGORY                                DESCRIPTION  \\\n",
       "616   3.721389  Physician           Physician Resident Admission Note   \n",
       "617   3.721389  Physician           Physician Resident Admission Note   \n",
       "618   7.371389  Physician   Physician Attending Admission Note - MICU   \n",
       "619   7.371389  Physician   Physician Attending Admission Note - MICU   \n",
       "620  10.004722     Nursing                      Nursing Progress Note   \n",
       "\n",
       "                                                  TEXT  \\\n",
       "616  Chief Complaint:\\nCC: Hypertensive Urgecny and...   \n",
       "617  Chief Complaint:\\nCC: Hypertensive Urgecny and...   \n",
       "618  Chief Complaint:\\nHTN urgency    I saw and exa...   \n",
       "619  Chief Complaint:\\nHTN urgency    I saw and exa...   \n",
       "620  Admitted from ED with hypertensive crisis.\\nSB...   \n",
       "\n",
       "                                              filename  PATIENT_ID  EPISODE_ID  \n",
       "616  /mnt/data01/mimic-3/benchmark-small/train/109/...         109          16  \n",
       "617  /mnt/data01/mimic-3/benchmark-small/train/109/...         109          16  \n",
       "618  /mnt/data01/mimic-3/benchmark-small/train/109/...         109          16  \n",
       "619  /mnt/data01/mimic-3/benchmark-small/train/109/...         109          16  \n",
       "620  /mnt/data01/mimic-3/benchmark-small/train/109/...         109          16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hours</th>\n      <th>CATEGORY</th>\n      <th>DESCRIPTION</th>\n      <th>TEXT</th>\n      <th>filename</th>\n      <th>PATIENT_ID</th>\n      <th>EPISODE_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>616</th>\n      <td>3.721389</td>\n      <td>Physician</td>\n      <td>Physician Resident Admission Note</td>\n      <td>Chief Complaint:\\nCC: Hypertensive Urgecny and...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/109/...</td>\n      <td>109</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>617</th>\n      <td>3.721389</td>\n      <td>Physician</td>\n      <td>Physician Resident Admission Note</td>\n      <td>Chief Complaint:\\nCC: Hypertensive Urgecny and...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/109/...</td>\n      <td>109</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>618</th>\n      <td>7.371389</td>\n      <td>Physician</td>\n      <td>Physician Attending Admission Note - MICU</td>\n      <td>Chief Complaint:\\nHTN urgency    I saw and exa...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/109/...</td>\n      <td>109</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>619</th>\n      <td>7.371389</td>\n      <td>Physician</td>\n      <td>Physician Attending Admission Note - MICU</td>\n      <td>Chief Complaint:\\nHTN urgency    I saw and exa...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/109/...</td>\n      <td>109</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>10.004722</td>\n      <td>Nursing</td>\n      <td>Nursing Progress Note</td>\n      <td>Admitted from ED with hypertensive crisis.\\nSB...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/109/...</td>\n      <td>109</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "notes[notes[\"EPISODE_ID\"] > 5].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Hours\n",
       "               count\n",
       "CATEGORY            \n",
       "General           23\n",
       "Nursing          502\n",
       "Nursing/other     50\n",
       "Nutrition         13\n",
       "Pharmacy           2\n",
       "Physician        333\n",
       "Radiology        119\n",
       "Rehab Services     8\n",
       "Respiratory       75\n",
       "Social Work        1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Hours</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>CATEGORY</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>General</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>Nursing</th>\n      <td>502</td>\n    </tr>\n    <tr>\n      <th>Nursing/other</th>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>Nutrition</th>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>Pharmacy</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Physician</th>\n      <td>333</td>\n    </tr>\n    <tr>\n      <th>Radiology</th>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>Rehab Services</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>Respiratory</th>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>Social Work</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "notes[[\"Hours\", \"CATEGORY\"]].groupby(\"CATEGORY\").agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of notes: 50\n"
     ]
    }
   ],
   "source": [
    "# Restrict the number of notes for processing\n",
    "\n",
    "#category = [\"Nursing\", \"Nursing/other\", 'General', 'Physician ']  # or None\n",
    "category = [\"Nursing/other\"]  # or None\n",
    "\n",
    "if category != None:\n",
    "    notes = notes[notes['CATEGORY'].isin(category)]\n",
    "\n",
    "print('Number of notes: %d' %len(notes.index))\n",
    "\n",
    "# nlp = spacy.load('en_core_sci_md', disable=['tagger','ner', 'lemmatizer'])\n",
    "# nlp.add_pipe('sbd_component', before='parser')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Bio_ClinicalBERT model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't bother trying to run the pipeline without a GPU\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "pipe = pipeline('feature-extraction', model=model, \n",
    "                tokenizer=tokenizer, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.8.1+cu102\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7f424ed61546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getCompiledVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda compiled version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/bin/anaconda3/envs/benchmark/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/bin/anaconda3/envs/benchmark/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "# import torch \n",
    "# print(torch.__version__)\n",
    "# print(torch.cuda.current_device())\n",
    "# print(torch._C._cuda_getCompiledVersion(), 'cuda compiled version')\n",
    "# print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.03993183,  0.28045335, -0.22612181, ..., -0.36056122,\n",
       "         0.02098022, -0.07117227],\n",
       "       [ 0.26059052,  0.28010404, -0.19884744, ..., -0.41535103,\n",
       "         0.55648178, -0.36985204]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "features = pipe(['Respiratory CAre Pt received from ED intubated for airway protection.And then another sentenc',\n",
    "                  'Coughing and gagging with Sx, swallowing frequently with irritation of ETT.']  ,\n",
    "                pad_to_max_length=True)\n",
    "features = np.squeeze(features)\n",
    "features = features[:,0,:]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_embeddings(text, pipe):\n",
    "    sents = text.split('\\n')[:-1]\n",
    "    #sents = list(map(lambda x: x[:50], sents))\n",
    "    start_idx = 0\n",
    "    while True:\n",
    "        try:\n",
    "            sent_features = pipe(sents[start_idx:] ,pad_to_max_length=True)\n",
    "        except BaseException as e:\n",
    "            start_idx += 1\n",
    "\n",
    "            if start_idx >= len(sents):\n",
    "                print(\"\\nError in get_embeddings()\")\n",
    "                print('# of sentences: '+ str(len(sents)))\n",
    "                sent_len = [len(x) for x in sents]\n",
    "                print(sent_len)\n",
    "                sent_features = None\n",
    "                break\n",
    "\n",
    "            print(\"Dropping sentence: \" + sents[start_idx-1])\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    if sent_features is not None:\n",
    "        try:\n",
    "            sent_features = np.squeeze(sent_features)[:,0,:]\n",
    "        except BaseException as e:\n",
    "            print(f\"Error squeezing sent_features - {e}\")\n",
    "            sent_features = None\n",
    "    \n",
    "    return sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [01:05<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "notes[\"bert_embeddings\"] = notes[\"TEXT\"].progress_apply(get_embeddings, args=(pipe,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7, 768)\n(47, 768)\n(5, 768)\n(71, 768)\n(43, 768)\n(5, 768)\n(51, 768)\n(45, 768)\n(6, 768)\n(28, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(notes[\"bert_embeddings\"].iloc[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Hours       CATEGORY DESCRIPTION  \\\n",
       "count    50.000000             50          50   \n",
       "unique         NaN              1           1   \n",
       "top            NaN  Nursing/other      Report   \n",
       "freq           NaN             50          50   \n",
       "mean     45.648222            NaN         NaN   \n",
       "std      31.821967            NaN         NaN   \n",
       "min       4.174444            NaN         NaN   \n",
       "25%      21.070764            NaN         NaN   \n",
       "50%      44.101111            NaN         NaN   \n",
       "75%      62.639236            NaN         NaN   \n",
       "max     129.083611            NaN         NaN   \n",
       "\n",
       "                                                     TEXT  \\\n",
       "count                                                  50   \n",
       "unique                                                 50   \n",
       "top     Nursing Addendum Pt. stated this eve that she ...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                 filename  PATIENT_ID  \\\n",
       "count                                                  50   50.000000   \n",
       "unique                                                  7         NaN   \n",
       "top     /mnt/data01/mimic-3/benchmark-small/train/191/...         NaN   \n",
       "freq                                                   20         NaN   \n",
       "mean                                                  NaN  223.700000   \n",
       "std                                                   NaN   72.249356   \n",
       "min                                                   NaN  109.000000   \n",
       "25%                                                   NaN  191.000000   \n",
       "50%                                                   NaN  191.000000   \n",
       "75%                                                   NaN  222.000000   \n",
       "max                                                   NaN  345.000000   \n",
       "\n",
       "        EPISODE_ID                                    bert_embeddings  \n",
       "count    50.000000                                                 50  \n",
       "unique         NaN                                                 50  \n",
       "top            NaN  [[0.2806047201156616, 0.03838098421692848, -0....  \n",
       "freq           NaN                                                  1  \n",
       "mean      2.600000                                                NaN  \n",
       "std       1.726149                                                NaN  \n",
       "min       1.000000                                                NaN  \n",
       "25%       2.000000                                                NaN  \n",
       "50%       2.000000                                                NaN  \n",
       "75%       3.000000                                                NaN  \n",
       "max       8.000000                                                NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hours</th>\n      <th>CATEGORY</th>\n      <th>DESCRIPTION</th>\n      <th>TEXT</th>\n      <th>filename</th>\n      <th>PATIENT_ID</th>\n      <th>EPISODE_ID</th>\n      <th>bert_embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50.000000</td>\n      <td>50</td>\n      <td>50</td>\n      <td>50</td>\n      <td>50</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>Nursing Addendum Pt. stated this eve that she ...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/191/...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[[0.2806047201156616, 0.03838098421692848, -0....</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>50</td>\n      <td>50</td>\n      <td>1</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>45.648222</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>223.700000</td>\n      <td>2.600000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>31.821967</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>72.249356</td>\n      <td>1.726149</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.174444</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>109.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>21.070764</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>191.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>44.101111</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>191.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>62.639236</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>222.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>129.083611</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>345.000000</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "notes.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Hours       CATEGORY DESCRIPTION  \\\n",
       "3  7.351111  Nursing/other      Report   \n",
       "\n",
       "                                                TEXT  \\\n",
       "3  Respiratory CAre Pt received from ED intubated...   \n",
       "\n",
       "                                            filename  PATIENT_ID  EPISODE_ID  \\\n",
       "3  /mnt/data01/mimic-3/benchmark-small/test/345/e...         345           1   \n",
       "\n",
       "                                     bert_embeddings  \n",
       "3  [[-0.2339353859424591, -0.19446542859077454, -...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hours</th>\n      <th>CATEGORY</th>\n      <th>DESCRIPTION</th>\n      <th>TEXT</th>\n      <th>filename</th>\n      <th>PATIENT_ID</th>\n      <th>EPISODE_ID</th>\n      <th>bert_embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>7.351111</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>Respiratory CAre Pt received from ED intubated...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n      <td>345</td>\n      <td>1</td>\n      <td>[[-0.2339353859424591, -0.19446542859077454, -...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "notes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes[\"bert_embeddings_list\"] = notes[\"bert_embeddings\"].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "type(notes[\"bert_embeddings_list\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Getting array sizes: 100%|██████████| 7/7 [00:00<00:00, 362.03it/s]11 notes use 3504 bytes of memory\n",
      "2 notes use 480 bytes of memory\n",
      "20 notes use 5776 bytes of memory\n",
      "7 notes use 1880 bytes of memory\n",
      "6 notes use 1528 bytes of memory\n",
      "2 notes use 248 bytes of memory\n",
      "2 notes use 632 bytes of memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.memory_usage(index=False, deep=True)\n",
    "\n",
    "filenames = list(notes[\"filename\"].unique().tolist())\n",
    "for filename in tqdm(filenames, desc=\"Getting array sizes\"):\n",
    "    df = notes[notes[\"filename\"] == filename][[\"Hours\", \"CATEGORY\", \"DESCRIPTION\", \"bert_embeddings\", \"bert_embeddings_list\"]]\n",
    "    size = 0\n",
    "    note_num = 0\n",
    "    for i in range(len(df)):\n",
    "        array = df[\"bert_embeddings_list\"].iloc[i]\n",
    "        size += sys.getsizeof(array)\n",
    "        note_num += 1\n",
    "\n",
    "    print(f\"{note_num} notes use {size} bytes of memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Writing embedding files: 100%|██████████| 7/7 [00:00<00:00, 22.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write out a new notes file with the embeddings\n",
    "# aflanders: This is going to take too long and take up too much space\n",
    "# The embeddings will be longer than the notes themselves. Each patient/episode\n",
    "# can go from 500Kb to 18Mb\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "filenames = list(notes[\"filename\"].unique().tolist())\n",
    "for filename in tqdm(filenames, desc=\"Writing embedding files\"):\n",
    "    df = notes[notes[\"filename\"] == filename][[\"Hours\", \"CATEGORY\", \"DESCRIPTION\", \"bert_embeddings_list\"]]\n",
    "    df = df.set_index(\"Hours\")\n",
    "    write_file = filename.replace(\"_notes_sent.csv\", \"_notes_bert.parquet\")\n",
    "    df.to_parquet(write_file)\n",
    "    # with open(write_file, \"w\") as f:\n",
    "        # df.to_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/data01/mimic-3/benchmark-small/train/109/episode8_notes_bert.parquet\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                CATEGORY DESCRIPTION  \\\n",
       "Hours                                  \n",
       "11.429167  Nursing/other      Report   \n",
       "25.862500  Nursing/other      Report   \n",
       "\n",
       "                                        bert_embeddings_list  \n",
       "Hours                                                         \n",
       "11.429167  [[0.3830723762512207, 0.3420313596725464, 0.01...  \n",
       "25.862500  [[0.28190192580223083, 0.214814230799675, -0.1...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CATEGORY</th>\n      <th>DESCRIPTION</th>\n      <th>bert_embeddings_list</th>\n    </tr>\n    <tr>\n      <th>Hours</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11.429167</th>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>[[0.3830723762512207, 0.3420313596725464, 0.01...</td>\n    </tr>\n    <tr>\n      <th>25.862500</th>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>[[0.28190192580223083, 0.214814230799675, -0.1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df = pd.read_parquet(write_file)\n",
    "print(write_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}